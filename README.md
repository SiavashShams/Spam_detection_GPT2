# Natural Language Processing with GPT Models

This repository contains two Jupyter Notebooks demonstrating the use of GPT models for different NLP tasks. These notebooks were developed as part of a course assignment in Deep Learning and Natural Language Processing.

## Notebooks

### 1. GPT_LM.ipynb

**Description:** This notebook focuses on language modeling using GPT. It involves training a GPT model on a custom dataset to perform language modeling tasks. The notebook includes data preprocessing, model training, and evaluation of the model's performance.

**Key Sections:**
- Data Loading and Preprocessing
- Model Definition
- Training the GPT Model
- Evaluating the Language Model
- Generating Text with the Trained Model

### 2. SPAM_with_GPT2.ipynb

**Description:** This notebook addresses the problem of spam detection using a GPT-2 model. It involves fine-tuning a pre-trained GPT-2 model on a spam detection dataset. The notebook includes steps for data preparation, model fine-tuning, and evaluation of the model's ability to classify spam and non-spam messages.

**Key Sections:**
- Data Preparation
- Fine-tuning GPT-2 for Spam Detection
- Model Evaluation
- Predicting Spam Messages
